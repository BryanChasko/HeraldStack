```markdown
# Best Practices for Integrating Anthropic Research into HARALD’s Modular LLM Stack

**Version:** 2025-07-22  
**Author:** Bryan Chasko

## Context

This document outlines integration principles, architectural considerations, and
best practices for incorporating Anthropic’s alignment-first research into
HARALD’s multi-agent, model-agnostic LLM stack. While the Claude family serves
as a leading example, we prioritize Anthropic’s systemic innovations—such as
Constitutional AI, refusal modeling, and dialogical transparency—as design
primitives to inform and augment HARALD’s agents and routing logic.
```
